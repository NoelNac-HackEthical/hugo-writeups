{"make-htb-wordlist":{"description":"Construit et installe une wordlist orientée HTB (vhost/subdomains) à partir de SecLists (+ seed FAST), normalisée et limitée à 5000 entrées.","presentation_md":"**make-htb-wordlist — Master DNS/VHOST orientée HTB (5000 entrées)**\n\nCe script assemble une wordlist « maison » optimisée pour les CTF HTB afin d’alimenter\nle vhost-fuzzing (ex. avec mon-subdomains). Il combine plusieurs sources SecLists et\nune petite liste « FAST » prioritaire, applique des règles de normalisation strictes,\ndéduplique/ordonne, puis tronque proprement à 5000 lignes.\n\nSources et pipeline :\n- SecLists : DNS top1million-5000 + Web-Content raft-small (+ raft-medium si non désactivé) ;\n- seed « FAST » (admin, dev, api, staging, …) placée en tête pour prioriser les hits ;\n- normalisation : minuscules, charset [a-z0-9-], pas de « -- », ni tiret en début/fin,\n  longueur 3..24 (paramétrable), optionnelle autorisation de début par chiffre ;\n- déduplication ordonnée, puis coupe à 5000 entrées max.\n\nSortie et installation :\n- chemin par défaut : /usr/share/wordlists/htb-dns-vh-5000.txt (droits 644) ;\n- tentative d’installation de SecLists via apt (désactivable avec --no-install) ;\n- affichage d’un aperçu (Top 10) pour vérification rapide.\n\nOptions utiles :\n- --out FILE            : fichier de sortie personnalisé ;\n- --no-install          : n’installe pas SecLists automatiquement ;\n- --no-medium           : exclut raft-medium pour une liste plus compacte ;\n- --minlen / --maxlen   : borne la longueur des tokens ;\n- --allow-digit-start   : autorise un début par chiffre.\n\nExemples :\n  ./make-htb-wordlist\n  ./make-htb-wordlist --no-medium --out /tmp/htb-5000.txt\n  ./make-htb-wordlist --minlen 2 --maxlen 20 --allow-digit-start\n\nUsage recommandé :\n- générer/mettre à jour la master une fois sur la machine de lab ;\n- l’utiliser ensuite dans mon-subdomains (modes fast/medium/large via head) ;\n- conserver le fichier versionné/packagé si besoin pour reproductibilité.","sha256":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/make-htb-wordlist.sha256","url":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/make-htb-wordlist","usage":"","version":"1.0.0"},"mon-nmap":{"description":"Automatise scans Nmap (TCP full, -A, UDP) + passes NSE (web/ssl/vuln/smb) avec affichage de progression ; lance mon-nmap-analyze si demandé ; affiche toujours summary.txt en fin.","presentation_md":"Mon-Nmap — Outil d’énumération Nmap pour CTF / pentest\n\nCe script automatise la séquence de scans systématiques en phase\nd’énumération : scan TCP complet (1-65535), scan \"agressif\" (-A)\nsur les ports détectés, scan UDP (top-20 ou complet), et passes NSE\nciblées (web/ssl/vuln/smb) avec affichage de la progression.\n\n- Génère des sorties prêtes pour les writeups : summary.txt et summary.md\n- Peut lancer une analyse post-scan (mon-nmap-analyze) et injecter le\n  résumé des vulnérabilités HIGH dans les summaries\n- Comportement conservateur : résultats isolés dans nmap_<cible>/\n\n1. Lancer un scan complet : `mon-nmap target.htb`\n2. Ajouter tous les NSE et l’analyse : `mon-nmap --nse-all --analyze target.htb`\n3. Forcer l’UDP complet : `mon-nmap --udp-all target.htb`\n\nExemple rapide :\n`mon-nmap --nse-all --analyze 10.10.10.10`\n\nAstuce : adapter les passes NSE selon le contexte pour gagner du temps.","sha256":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/mon-nmap.sha256","url":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/mon-nmap","usage":"","version":"1.2.0"},"mon-nmap-analyze":{"description":"Analyse les sorties de mon-nmap et agrège les vulnérabilités/indicateurs en TXT/MD/JSON. Exclut les HIGH dont Evidence","presentation_md":"Mon-Nmap-Analyze — agrégation des vulnérabilités détectées par Nmap/NSE\n\nCe script lit les fichiers produits par `mon-nmap` (2-aggressive_scan.txt, 4-nse-*.txt)\net remonte les marqueurs typiques :\n- blocs **VULNERABLE** (scripts --script=vuln) — Evidence normalisée en `VULNERABLE`,\n- méthodes HTTP risquées (PUT/DELETE/TRACE/TRACK),\n- indices de chiffrement SSL/TLS faibles (RC4/MD5/SHA1/SSLv2/SSLv3/3DES/SWEET32/weak/deprecated),\n- vulnérabilité SMB **MS17-010 (EternalBlue)**.\n\nGénère (même ordre de tri pour les 3 formats) :\n- `vulns.txt` (Count, Title, Severity, Evidence, Ports, Services, Sources),\n- `vulns.md` (prêt pour Hugo),\n- `vulns.json` (structuré).\n\nEXCLUSION : les entrées `HIGH` dont `Evidence` == \"VULNERABLE\" sont filtrées des trois sorties.\n\nTri: Severity(HIGH>MEDIUM>LOW>INFO>autres) → Count(desc) → Title(asc)\n\nExemple :\n  mon-nmap 10.10.10.10 && mon-nmap-analyze 10.10.10.10\n  mon-nmap-analyze --dir nmap_10.10.10.10","sha256":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/mon-nmap-analyze.sha256","url":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/mon-nmap-analyze","usage":"","version":"1.0.5"},"mon-recoweb":{"description":"Automatise la découverte de répertoires et fichiers web (whatweb + ffuf) et génère des résumés structurés pour les writeups.","presentation_md":"**mon-recoweb — Découverte web ciblée pour CTF / pentest**\n\nCe script automatise la reconnaissance web d'une cible (ex. mon-site.htb) : il lance\nd'abord une identification de surface avec WhatWeb, puis plusieurs passes de fuzzing\navec ffuf pour détecter répertoires et fichiers intéressants (par extension).\n\nPrincipes et usages (tutoriel succinct) :\n- passe 1 : identification rapide (WhatWeb) pour orienter les tests ;\n- passe 2 : fuzzing \"common\" (wordlist courte) pour trouver rapidement les chemins fréquents ;\n- passe 3 : tests par extension (ex. .php, .html, .txt) pour capturer fichiers référencés ;\n- optionnel : passe étendue (wordlist exhaustive) — à réserver au lab car elle est\n  plus lente et bruyante (risque de bannissement / WAF).\n\nComportement concret :\n- filtres automatiques : le script essaie de déduire des tailles de pages d'erreur et\n  applique -fs / -fc 404 par défaut ; tu peux désactiver via --no-filters ;\n- sorties : tout est écrit dans un dossier dédié `mon-recoweb_<cible>` (ex. mon-recoweb_mon-site.htb)\n  avec au minimum : whatweb.txt, summary_dirs.txt, summary_files.txt ;\n- options usuelles : changer la wordlist (-w), limiter la vitesse (-p), définir les extensions (-x),\n  forcer http/https (--http / --https) ou ajuster le nombre de threads (-T).\n\nBonnes pratiques :\n- commencer toujours par la passe courte, trier/valider manuellement les résultats,\n  puis lancer une passe étendue uniquement si le contexte le permet (lab, autorisation, etc.) ;\n- adapter la tempo et le nombre de threads en fonction de la cible pour éviter les blocages.\n\nExemple d'usage :\n  ./mon-recoweb mon-site.htb\n  ./mon-recoweb --no-filters -w /chemin/ma-liste.txt -x php,html -T 60 mon-site.htb\n\nPrésentation concise : outil de reconnaissance web conçu pour produire des résultats\nexploitables immédiatement et faciles à inclure dans un writeup.","sha256":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/mon-recoweb.sha256","url":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/mon-recoweb","usage":"","version":"1.0.0"},"mon-recoweb-analyze":{"description":"Analyse les sorties de mon-recoweb et produit summary.txt et summary.md","presentation_md":"mon-recoweb-analyse — Agrège whatweb.txt + summary_dirs.txt + summary_files.txt\nProduit deux fichiers lisibles pour inclusion dans un writeup :\n - summary.txt (plain text, compact)\n - summary.md  (markdown, structuré pour Hugo)\nUsage:\n  mon-recoweb-analyze <outdir>\n  mon-recoweb-analyze --target <outdir>\n  mon-recoweb-analyze            # tente d'inférer le dernier mon-recoweb_* dans PWD\nIntégration rapide : appeler 'mon-recoweb-analyze \"${OUTDIR}\"' depuis mon-recoweb lorsque\nl'utilisateur passe l'option --analyze.","sha256":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/mon-recoweb-analyze.sha256","url":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/mon-recoweb-analyze","usage":"mon-recoweb-analyze  v1.0.0\n/work/mon-recoweb-analyze: line 37: usage: command not found\nmon-recoweb-analyze v1.0.0\n/work/mon-recoweb-analyze: line 37: usage: command not found","version":"mon-recoweb-analyze v1.0.0"},"mon-subdomains":{"description":"Découverte de sous-domaines par vhost-fuzzing (ffuf) avec baseline anti-wildcard, modes fast/medium/large et options d'ajout dans /etc/hosts.","presentation_md":"**mon-subdomains — Découverte de vhosts pour CTF / pentest**\n\nCe script automatise la recherche de sous-domaines en se basant sur du vhost-fuzzing :\nil teste des noms Host.FQDN en interrogeant l'IP cible via ffuf et extrait les hôtes\nvalides (ex. api.mon-site.htb, admin.mon-site.htb). La recherche se fait soit à partir\nd'une \"master\" orientée HTB soit via une wordlist custom.\n\nPrincipe de fonctionnement et sécurité :\n- sampling master : le script propose trois modes (fast/medium/large) qui utilisent\n  respectivement les 1000 / 2000 / 5000 premières lignes de la master (head) — rapide\n  vs exhaustif selon le besoin ;\n- anti-wildcard / baseline : il établit une baseline (code HTTP, taille, nombre de mots)\n  via un Host aléatoire pour filtrer les faux positifs (wildcards) en ajoutant -fs / -fw ;\n- sauvegarde / dry-run : l'option --save-hosts tente d'ajouter les hôtes trouvés dans\n  /etc/hosts (création d'un backup) ; --dry-run-hosts affiche ce qui serait ajouté\n  sans écrire (utile et conseillé avant toute modification système).\n\nOptions pratiques et recommandations :\n- par défaut la master est : /usr/share/wordlists/htb-dns-vh-5000.txt (modifiable via --master) ;\n- mode FAST/MEDIUM/LARGE : choisir FAST en reconnaissance rapide, LARGE uniquement en lab ;\n- --strict / --codes : pour restreindre les codes HTTP retenus (ex. 200,401,403) et diminuer le bruit ;\n- --https / auto-detection : le script détecte automatiquement http/https mais on peut forcer ;\n- pour que le fuzzing vhost fonctionne, il faut que l'IP cible soit résolue — ajoute l'entrée\n  dans /etc/hosts si nécessaire (ou utiliser --save-hosts après vérification).\n\nRègles d'or :\n- commencer en fast, valider manuellement les hôtes trouvés, puis relancer medium/large en lab ;\n- ne pas activer --save-hosts sans vérification (préférer --dry-run-hosts pour contrôler) ;\n- adapter threads/timeout selon l'environnement pour éviter les blocages ou détections.\n\nExemples :\n  ./mon-subdomains mon-site.htb --fast\n  ./mon-subdomains mon-site.htb --medium --strict --save-hosts\n  ./mon-subdomains mon-site.htb --custom /chemin/ma-liste.txt --https --dry-run-hosts\n\nPrésentation concise : outil de vhost-fuzzing robuste, conçu pour produire une liste\nde sous-domaines exploitables et facilement vérifiables pour inclusion dans un writeup.","sha256":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/mon-subdomains.sha256","url":"https://github.com/NoelNac-HackEthical/mes-scripts/releases/download/r-2025-10-20-1546/mon-subdomains","usage":"","version":"1.0.0"}}
